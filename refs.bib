% BLOG POSTS
@online{TerrainFromNoise,
    author = {Amit, Patel},
    title = {Making maps with noise functions},
    date = {2022},
    url = {https://www.redblobgames.com/maps/terrain-from-noise/}
}

@online{UnderstandingPerlinNoise,
    author = {Adrian Biagioli},
    title = {Understanding Perlin Noise},
    date = {09-2014},
    url = {https://adrianb.io/2014/08/09/perlinnoise.html}
}

@online{ProceduralPatterns,
    title = {Value Noise and Procedural Patterns: Part 1},
    author = {Scratchapixel},
    date = {},
    url = {https://www.scratchapixel.com/lessons/procedural-generation-virtual-worlds/procedural-patterns-noise-part-1/simple-pattern-examples.html}
}

@electronic{TheBookOfShaders13,
    author = {Patricio Gonzalez Vivo and Jen Lowe},
    title = {The Book of Shaders: Fractal Brownian Motion},
    date = {},
    url = {https://thebookofshaders.com/13/}
}


% DNN with brown

@inproceedings{DDPM,
     author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
     booktitle = {Advances in Neural Information Processing Systems},
     editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
     pages = {6840--6851},
     publisher = {Curran Associates, Inc.},
     title = {Denoising Diffusion Probabilistic Models},
     url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
     volume = {33},
     year = {2020}
}


@article{SDENet,
  author    = {Lingkai Kong and
               Jimeng Sun and
               Chao Zhang},
  title     = {SDE-Net: Equipping Deep Neural Networks with Uncertainty Estimates},
  journal   = {CoRR},
  volume    = {abs/2008.10546},
  year      = {2020},
  url       = {https://arxiv.org/abs/2008.10546},
  eprinttype = {arXiv},
  eprint    = {2008.10546},
  timestamp = {Thu, 02 Feb 2023 16:04:34 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2008-10546.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ItoEnsemble,
  title={Robust Ensembles of Neural Networks using It\^{o} Processes},
  author={Jha, Sumit Kumar and Jha, Susmit and Ewetz, Rickard and Velasquez, Alvaro},
  year={2021},
  journal={ICLR 2021 Conference}
}

@misc{ItoProcessSGD,
      title={Bayesian interpretation of SGD as Ito process}, 
      author={Soma Yokoi and Issei Sato},
      year={2019},
      eprint={1911.09011},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{ScalingDRN,
      title={Scaling Properties of Deep Residual Networks}, 
      author={Alain-Sam Cohen and Rama Cont and Alain Rossier and Renyuan Xu},
      year={2021},
      eprint={2105.12245},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ItoWave,
      title={It\^{o} Wave: It\^{o} Stochastic Differential Equation Is All You Need For Wave Generation}, 
      author={Shoule, Wu and Ziqiang, Shi},
      year={2022},
      eprint={2201.12519},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}

@misc{VQBB,
      title={VQBB: Image-to-image Translation with Vector Quantized Brownian Bridge}, 
      author={Bo Li and Kaitao Xue and Bin Liu and Yu-Kun Lai},
      year={2022},
      eprint={2205.07680},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{ItoTTS,
      title={It\^{o} TTS and It\^{o} Wave: Linear Stochastic Differential Equation Is All You Need For Audio Generation}, 
      author={Shoule, Wu and Ziqiang, Shi},
      year={2022},
      eprint={2105.07583},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}

@inproceedings{DiffusionVAE,
  title     = {Diffusion Variational Autoencoders},
  author    = {Perez Rey, Luis A. and Menkovski, Vlado and Portegies, Jim},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, IJCAI-20},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  pages     = {2704--2710},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/375},
  url       = {https://doi.org/10.24963/ijcai.2020/375},
}

@article{RiemannBrownVAE,
  title={Variational Autoencoders with Riemannian Brownian Motion Priors},
  author={Dimitris Kalatzis and David Eklund and Georgios Arvanitidis and S{\o}ren Hauberg},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.05227}
}

@misc{StableDiffusion,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{BrownianTransformers,
      title={The Brownian motion in the transformer model}, 
      author={Yingshi Chen},
      year={2021},
      eprint={2107.05264},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


%% THEORY
@article{DiffusionMaps,
title = {Diffusion maps},
journal = {Applied and Computational Harmonic Analysis},
volume = {21},
number = {1},
pages = {5-30},
year = {2006},
note = {Special Issue: Diffusion Maps and Wavelets},
issn = {1063-5203},
doi = {https://doi.org/10.1016/j.acha.2006.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S1063520306000546},
author = {Ronald R. Coifman and Stéphane Lafon},
keywords = {Diffusion processes, Diffusion metric, Manifold learning, Dimensionality reduction, Eigenmaps, Graph Laplacian},
abstract = {In this paper, we provide a framework based upon diffusion processes for finding meaningful geometric descriptions of data sets. We show that eigenfunctions of Markov matrices can be used to construct coordinates called diffusion maps that generate efficient representations of complex geometric structures. The associated family of diffusion distances, obtained by iterating the Markov matrix, defines multiscale geometries that prove to be useful in the context of data parametrization and dimensionality reduction. The proposed framework relates the spectral properties of Markov processes to their geometric counterparts and it unifies ideas arising in a variety of contexts such as machine learning, spectral graph theory and eigenmap methods.}
}

@misc{AttentionIsAllYouNeed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

%% MATH STUFF
@incollection{S096:17,
    author = {Peter, Kempthorne and Choongbum, Lee and Vasily, Strela and Jake, Xia},
    title = {Lecture 17: Stochastic Processes II},
    booktitle = {Topics in Mathematics with Applications in Finance--18.S096},
    year = 2013,
    organization = {Massachusetts Institute of Technology},
    address = {Cambridge MA},
    note = {MIT OpenCourseWare},
    url = {https://ocw.mit.edu/courses/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/resources/mit18_s096f13_lecnote17/},
}

@incollection{S096:18,
    author = {Peter, Kempthorne and Choongbum, Lee and Vasily, Strela and Jake, Xia},
   title = {Lecture 18: It\^{o} Calculus},
   booktitle = {Topics in Mathematics with Applications in Finance--18.S096},
   year = 2013,
   organization = {Massachusetts Institute of Technology},
   address = {Cambridge MA},
   note = {MIT OpenCourseWare},
   url = {https://ocw.mit.edu/courses/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/resources/mit18_s096f13_lecnote18/},
}

@misc{LayerNormInTransformer,
      title={On Layer Normalization in the Transformer Architecture}, 
      author={Ruibin Xiong and Yunchang Yang and Di He and Kai Zheng and Shuxin Zheng and Chen Xing and Huishuai Zhang and Yanyan Lan and Liwei Wang and Tie-Yan Liu},
      year={2020},
      eprint={2002.04745},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{VAE,
      title={An Introduction to Variational Inference}, 
      author={Ankush Ganguly and Samuel W. F. Earp},
      year={2021},
      eprint={2108.13083},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{Bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{PhoBert,
      title={PhoBERT: Pre-trained language models for Vietnamese}, 
      author={Dat Quoc Nguyen and Anh Tuan Nguyen},
      year={2020},
      eprint={2003.00744},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{ViT,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{SVTR,
      title={SVTR: Scene Text Recognition with a Single Visual Model}, 
      author={Yongkun Du and Zhineng Chen and Caiyan Jia and Xiaoting Yin and Tianlun Zheng and Chenxia Li and Yuning Du and Yu-Gang Jiang},
      year={2022},
      eprint={2205.00159},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{HSU,
  title={A brief introduction to Brownian motion on a Riemannian manifold},
  author={Hsu, Elton P},
  journal={một bài giảng của Viện Toán, Đại học Northwestern},
  year={2008},
  note={Mục 1.4 chứa lý thuyết cho phương pháp dùng phép chiếu trong nghiên cứu của $\Delta$VAE.}
}

